{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import phrasemachine\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('/Users/dylanhayashi/Desktop/Northwestern/NU_MSDS/453 - Natural Language Processing/453.1 - Natural Language Processing and Artificial Intelligence/DHB_MovieReview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dylanhayashi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dylanhayashi/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this once, they will be downloaded.\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_one = reviews.loc[0,'MovieReview']\n",
    "review_two = reviews.loc[1,'MovieReview']\n",
    "review_three = reviews.loc[2,'MovieReview']\n",
    "review_four = reviews.loc[3,'MovieReview']\n",
    "review_five = reviews.loc[4,'MovieReview']\n",
    "review_six = reviews.loc[5,'MovieReview']\n",
    "review_seven = reviews.loc[6,'MovieReview']\n",
    "review_eight = reviews.loc[7,'MovieReview']\n",
    "review_nine = reviews.loc[8,'MovieReview']\n",
    "review_ten = reviews.loc[0,'MovieReview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = [\n",
    "    'Paris','Liam Neeson','Liam','Neeson','CIA','Central Intelligence Agency','Albania','Europe','U2','Hollywood','Bryan',\n",
    "    'kidnap','action','fight','scenen','slavery','abduct','kill','torture','shoot','cliche','flight','vacation','victim',\n",
    "    'women','men','police','drug','trauma','character','airport','thrill','moral','human','traffick','trailer','review',\n",
    "    'rating','dialogue','production','direct','cinematography','PG-13','review','film','movie','spy','act','suspense',\n",
    "    'good','bad','best','worst','offensive','realistic','believable','terrible','great','again','watch','see','crime',\n",
    "    'organized crime'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>doc1_count</th>\n",
       "      <th>doc2_count</th>\n",
       "      <th>doc3_count</th>\n",
       "      <th>doc4_count</th>\n",
       "      <th>doc5_count</th>\n",
       "      <th>doc6_count</th>\n",
       "      <th>doc7_count</th>\n",
       "      <th>doc8_count</th>\n",
       "      <th>doc9_count</th>\n",
       "      <th>doc10_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paris</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liam Neeson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neeson</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>terrible</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>again</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Term doc1_count doc2_count doc3_count doc4_count doc5_count  \\\n",
       "0         Paris          6          1         11          0          0   \n",
       "0   Liam Neeson          0          0          0          0          1   \n",
       "0          Liam          0          0         12          0          1   \n",
       "0        Neeson          0          5          0          0          3   \n",
       "0           CIA          1          1          5          0          0   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "0      terrible          1          0          0          0          0   \n",
       "0         great          0          0          0          1          0   \n",
       "0         again          1          0          0          0          0   \n",
       "0         watch          2          1          0          0          2   \n",
       "0           see          4          3          3          3          5   \n",
       "\n",
       "   doc6_count doc7_count doc8_count doc9_count doc10_count  \n",
       "0           0          1          2          1           6  \n",
       "0           4          3          2          3           0  \n",
       "0           4          4          4          3           0  \n",
       "0           7          6          2          4           0  \n",
       "0           0          0          1          1           1  \n",
       "..        ...        ...        ...        ...         ...  \n",
       "0           0          0          0          0           1  \n",
       "0           5          0          3          0           0  \n",
       "0           0          1          0          0           1  \n",
       "0           0          3          0          0           2  \n",
       "0           4          2          5          8           4  \n",
       "\n",
       "[61 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequencies = pd.DataFrame(columns=['Term','doc1_count','doc2_count','doc3_count','doc4_count','doc5_count','doc6_count','doc7_count','doc8_count','doc9_count','doc10_count'])\n",
    "\n",
    "for term in term_list:\n",
    "\n",
    "    frequencies = pd.DataFrame(\n",
    "        [{\n",
    "            'Term':term,\n",
    "            'doc1_count':len(re.findall(term,review_one)),\n",
    "            'doc2_count':len(re.findall(term,review_two)),\n",
    "            'doc3_count':len(re.findall(term,review_three)),\n",
    "            'doc4_count':len(re.findall(term,review_four)),\n",
    "            'doc5_count':len(re.findall(term,review_five)),\n",
    "            'doc6_count':len(re.findall(term,review_six)),\n",
    "            'doc7_count':len(re.findall(term,review_seven)),\n",
    "            'doc8_count':len(re.findall(term,review_eight)),\n",
    "            'doc9_count':len(re.findall(term,review_nine)),\n",
    "            'doc10_count':len(re.findall(term,review_ten))\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    term_frequencies = pd.concat([term_frequencies,frequencies])\n",
    "\n",
    "term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stop words from nltk\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Pre-process dataset to remove punctuation\n",
    "def remove_punctuation(in_text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(in_text))\n",
    "    return text\n",
    "\n",
    "# Pre-process dataset to lower case it\n",
    "def lower_case(in_text):\n",
    "    # Convert to lowercase\n",
    "    text = in_text.lower()    \n",
    "    return text\n",
    "\n",
    "# Pre-process dataset to remove tags\n",
    "def remove_tags(in_text):    \n",
    "    # Remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",in_text)\n",
    "    return text\n",
    "\n",
    "# Pre-process dataset to remove special characters and digits\n",
    "def remove_special_chars_and_digits(in_text):\n",
    "    # Remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",in_text)\n",
    "    return text\n",
    "\n",
    "# Pre-process dataset to appy Stemming\n",
    "def apply_stemming(in_text):\n",
    "    stemmer=PorterStemmer()\n",
    "    word_list = nltk.word_tokenize(in_text)\n",
    "    output = ' '.join([stemmer.stem(w) for w in word_list])\n",
    "    return output\n",
    "\n",
    "# Pre-process dataset to apply Lemmatization\n",
    "def apply_lemmatization(in_text):\n",
    "    # Lemmatization\n",
    "    lem = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(in_text)\n",
    "    output = ' '.join([lem.lemmatize(w) for w in word_list])\n",
    "    return output\n",
    "\n",
    "# Remove stop words\n",
    "def remove_stop_words(in_text):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(in_text)  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    return filtered_sentence\n",
    "\n",
    "# Run Phase Machine\n",
    "def run_phrase_machine(in_text):\n",
    "    phrases=phrasemachine.get_phrases(in_text)\n",
    "    return phrases\n",
    "\n",
    "#Run Rake Keyword Extractor\n",
    "def run_rake(in_text):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(in_text)\n",
    "    rake_phrases= r.get_ranked_phrases()\n",
    "    return rake_phrases\n",
    "\n",
    "# Run NLTK Tokenizer\n",
    "def run_nltk_tokenizer(in_text):\n",
    "    tokens=nltk.word_tokenize(in_text)\n",
    "    return tokens\n",
    "\n",
    "# Run NLTK Sentence Tokenizer\n",
    "def run_nltk_sent_tokenizer(in_corpus):\n",
    "    sents = nltk.sent_tokenize(in_corpus)\n",
    "    return sents\n",
    "\n",
    "#Run word-ngram Tokenizer\n",
    "def run_nltk_tokenizer_word_ngrams(in_text, ngram_size):\n",
    "    n_grams = ngrams(nltk.word_tokenize(in_text), ngram_size)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "#Get Frequ Dist \n",
    "def get_freq_dist(terms):\n",
    "    all_counts = dict()\n",
    "    all_counts = FreqDist(terms)\n",
    "    return all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_one = run_nltk_sent_tokenizer(review_one)\n",
    "sentences_two = run_nltk_sent_tokenizer(review_two)\n",
    "sentences_three = run_nltk_sent_tokenizer(review_three)\n",
    "sentences_four = run_nltk_sent_tokenizer(review_four)\n",
    "sentences_five = run_nltk_sent_tokenizer(review_five)\n",
    "sentences_six = run_nltk_sent_tokenizer(review_six)\n",
    "sentences_seven = run_nltk_sent_tokenizer(review_seven)\n",
    "sentences_eight = run_nltk_sent_tokenizer(review_eight)\n",
    "sentences_nine = run_nltk_sent_tokenizer(review_nine)\n",
    "sentences_ten = run_nltk_sent_tokenizer(review_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To save you the time in either watching this film or reading my critique of it, here is a brief summary: This film is the worst film I have ever seen.\n",
      "===================NLTK Tokenizer===================\n",
      "['To', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', ',', 'here', 'is', 'a', 'brief', 'summary', ':', 'This', 'film', 'is', 'the', 'worst', 'film', 'I', 'have', 'ever', 'seen', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['To save', 'save you', 'you the', 'the time', 'time in', 'in either', 'either watching', 'watching this', 'this film', 'film or', 'or reading', 'reading my', 'my critique', 'critique of', 'of it', 'it ,', ', here', 'here is', 'is a', 'a brief', 'brief summary', 'summary :', ': This', 'This film', 'film is', 'is the', 'the worst', 'worst film', 'film I', 'I have', 'have ever', 'ever seen', 'seen .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['To save you', 'save you the', 'you the time', 'the time in', 'time in either', 'in either watching', 'either watching this', 'watching this film', 'this film or', 'film or reading', 'or reading my', 'reading my critique', 'my critique of', 'critique of it', 'of it ,', 'it , here', ', here is', 'here is a', 'is a brief', 'a brief summary', 'brief summary :', 'summary : This', ': This film', 'This film is', 'film is the', 'is the worst', 'the worst film', 'worst film I', 'film I have', 'I have ever', 'have ever seen', 'ever seen .']\n",
      "===================Phrase Machine===================\n",
      "worst film\n",
      "===================Rake===================\n",
      "['ever seen', 'either watching', 'brief summary', 'worst film', 'film', 'film', 'time', 'save', 'reading', 'critique']\n",
      "===================NLTK Tokenizer===================\n",
      "['To', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', ',', 'here', 'is', 'a', 'brief', 'summary', ':', 'This', 'film', 'is', 'the', 'worst', 'film', 'I', 'have', 'ever', 'seen', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['to', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', ',', 'here', 'is', 'a', 'brief', 'summary', ':', 'this', 'film', 'is', 'the', 'worst', 'film', 'i', 'have', 'ever', 'seen', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['To', 'save', 'time', 'either', 'watching', 'film', 'reading', 'critique', ',', 'brief', 'summary', ':', 'This', 'film', 'worst', 'film', 'I', 'ever', 'seen', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['To', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', 'here', 'is', 'a', 'brief', 'summary', 'This', 'film', 'is', 'the', 'worst', 'film', 'I', 'have', 'ever', 'seen']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['To', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', ',', 'here', 'is', 'a', 'brief', 'summary', ':', 'This', 'film', 'is', 'the', 'worst', 'film', 'I', 'have', 'ever', 'seen', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['To', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', 'here', 'is', 'a', 'brief', 'summary', 'This', 'film', 'is', 'the', 'worst', 'film', 'I', 'have', 'ever', 'seen']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['to', 'save', 'you', 'the', 'time', 'in', 'either', 'watch', 'thi', 'film', 'or', 'read', 'my', 'critiqu', 'of', 'it', ',', 'here', 'is', 'a', 'brief', 'summari', ':', 'thi', 'film', 'is', 'the', 'worst', 'film', 'i', 'have', 'ever', 'seen', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['To', 'save', 'you', 'the', 'time', 'in', 'either', 'watching', 'this', 'film', 'or', 'reading', 'my', 'critique', 'of', 'it', ',', 'here', 'is', 'a', 'brief', 'summary', ':', 'This', 'film', 'is', 'the', 'worst', 'film', 'I', 'have', 'ever', 'seen', '.']\n",
      "This film is atrocious.\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'film', 'is', 'atrocious', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['This film', 'film is', 'is atrocious', 'atrocious .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['This film is', 'film is atrocious', 'is atrocious .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['film', 'atrocious']\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'film', 'is', 'atrocious', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['this', 'film', 'is', 'atrocious', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['This', 'film', 'atrocious', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['This', 'film', 'is', 'atrocious']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['This', 'film', 'is', 'atrocious', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['This', 'film', 'is', 'atrocious']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['thi', 'film', 'is', 'atroci', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['This', 'film', 'is', 'atrocious', '.']\n",
      "This film is so unbelievably awful that all the writers, directors, producers and cast that worked on it should be sent to the Hague and tried for crimes against humanity.\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writers', ',', 'directors', ',', 'producers', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'Hague', 'and', 'tried', 'for', 'crimes', 'against', 'humanity', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['This film', 'film is', 'is so', 'so unbelievably', 'unbelievably awful', 'awful that', 'that all', 'all the', 'the writers', 'writers ,', ', directors', 'directors ,', ', producers', 'producers and', 'and cast', 'cast that', 'that worked', 'worked on', 'on it', 'it should', 'should be', 'be sent', 'sent to', 'to the', 'the Hague', 'Hague and', 'and tried', 'tried for', 'for crimes', 'crimes against', 'against humanity', 'humanity .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['This film is', 'film is so', 'is so unbelievably', 'so unbelievably awful', 'unbelievably awful that', 'awful that all', 'that all the', 'all the writers', 'the writers ,', 'writers , directors', ', directors ,', 'directors , producers', ', producers and', 'producers and cast', 'and cast that', 'cast that worked', 'that worked on', 'worked on it', 'on it should', 'it should be', 'should be sent', 'be sent to', 'sent to the', 'to the Hague', 'the Hague and', 'Hague and tried', 'and tried for', 'tried for crimes', 'for crimes against', 'crimes against humanity', 'against humanity .']\n",
      "===================Phrase Machine===================\n",
      "crimes against humanity\n",
      "===================Rake===================\n",
      "['unbelievably awful', 'writers', 'worked', 'tried', 'sent', 'producers', 'humanity', 'hague', 'film', 'directors', 'crimes', 'cast']\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writers', ',', 'directors', ',', 'producers', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'Hague', 'and', 'tried', 'for', 'crimes', 'against', 'humanity', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['this', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writers', ',', 'directors', ',', 'producers', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'hague', 'and', 'tried', 'for', 'crimes', 'against', 'humanity', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['This', 'film', 'unbelievably', 'awful', 'writers', ',', 'directors', ',', 'producers', 'cast', 'worked', 'sent', 'Hague', 'tried', 'crimes', 'humanity', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['This', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writers', 'directors', 'producers', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'Hague', 'and', 'tried', 'for', 'crimes', 'against', 'humanity']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['This', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writers', ',', 'directors', ',', 'producers', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'Hague', 'and', 'tried', 'for', 'crimes', 'against', 'humanity', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['This', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writers', 'directors', 'producers', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'Hague', 'and', 'tried', 'for', 'crimes', 'against', 'humanity']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['thi', 'film', 'is', 'so', 'unbeliev', 'aw', 'that', 'all', 'the', 'writer', ',', 'director', ',', 'produc', 'and', 'cast', 'that', 'work', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'hagu', 'and', 'tri', 'for', 'crime', 'against', 'human', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['This', 'film', 'is', 'so', 'unbelievably', 'awful', 'that', 'all', 'the', 'writer', ',', 'director', ',', 'producer', 'and', 'cast', 'that', 'worked', 'on', 'it', 'should', 'be', 'sent', 'to', 'the', 'Hague', 'and', 'tried', 'for', 'crime', 'against', 'humanity', '.']\n",
      "In the first chapter of this film, three facts are established: 1.\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'the', 'first', 'chapter', 'of', 'this', 'film', ',', 'three', 'facts', 'are', 'established', ':', '1', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['In the', 'the first', 'first chapter', 'chapter of', 'of this', 'this film', 'film ,', ', three', 'three facts', 'facts are', 'are established', 'established :', ': 1', '1 .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['In the first', 'the first chapter', 'first chapter of', 'chapter of this', 'of this film', 'this film ,', 'film , three', ', three facts', 'three facts are', 'facts are established', 'are established :', 'established : 1', ': 1 .']\n",
      "===================Phrase Machine===================\n",
      "first chapter\n",
      "first chapter of this film\n",
      "chapter of this film\n",
      "three facts\n",
      "===================Rake===================\n",
      "['three facts', 'first chapter', 'film', 'established', '1']\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'the', 'first', 'chapter', 'of', 'this', 'film', ',', 'three', 'facts', 'are', 'established', ':', '1', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['in', 'the', 'first', 'chapter', 'of', 'this', 'film', ',', 'three', 'facts', 'are', 'established', ':', '1', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['In', 'first', 'chapter', 'film', ',', 'three', 'facts', 'established', ':', '1', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['In', 'the', 'first', 'chapter', 'of', 'this', 'film', 'three', 'facts', 'are', 'established']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['In', 'the', 'first', 'chapter', 'of', 'this', 'film', ',', 'three', 'facts', 'are', 'established', ':', '1', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['In', 'the', 'first', 'chapter', 'of', 'this', 'film', 'three', 'facts', 'are', 'established']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['in', 'the', 'first', 'chapter', 'of', 'thi', 'film', ',', 'three', 'fact', 'are', 'establish', ':', '1', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['In', 'the', 'first', 'chapter', 'of', 'this', 'film', ',', 'three', 'fact', 'are', 'established', ':', '1', '.']\n",
      "There exists a man.\n",
      "===================NLTK Tokenizer===================\n",
      "['There', 'exists', 'a', 'man', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['There exists', 'exists a', 'a man', 'man .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['There exists a', 'exists a man', 'a man .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['man', 'exists']\n",
      "===================NLTK Tokenizer===================\n",
      "['There', 'exists', 'a', 'man', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['there', 'exists', 'a', 'man', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['There', 'exists', 'man', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['There', 'exists', 'a', 'man']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['There', 'exists', 'a', 'man', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['There', 'exists', 'a', 'man']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['there', 'exist', 'a', 'man', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['There', 'exists', 'a', 'man', '.']\n",
      "He's pretty tough.\n",
      "===================NLTK Tokenizer===================\n",
      "['He', \"'s\", 'pretty', 'tough', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "[\"He 's\", \"'s pretty\", 'pretty tough', 'tough .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "[\"He 's pretty\", \"'s pretty tough\", 'pretty tough .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['pretty tough']\n",
      "===================NLTK Tokenizer===================\n",
      "['He', \"'s\", 'pretty', 'tough', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['he', \"'s\", 'pretty', 'tough', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['He', \"'s\", 'pretty', 'tough', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['He', 's', 'pretty', 'tough']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['He', \"'s\", 'pretty', 'tough', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['He', 's', 'pretty', 'tough']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['he', \"'s\", 'pretti', 'tough', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['He', \"'s\", 'pretty', 'tough', '.']\n",
      "2.\n",
      "===================NLTK Tokenizer===================\n",
      "['2', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['2 .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "[]\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['2']\n",
      "===================NLTK Tokenizer===================\n",
      "['2', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['2', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['2', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "[]\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['2', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "[]\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['2', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['2', '.']\n",
      "He loves his daughter very much.\n",
      "===================NLTK Tokenizer===================\n",
      "['He', 'loves', 'his', 'daughter', 'very', 'much', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['He loves', 'loves his', 'his daughter', 'daughter very', 'very much', 'much .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['He loves his', 'loves his daughter', 'his daughter very', 'daughter very much', 'very much .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['much', 'loves', 'daughter']\n",
      "===================NLTK Tokenizer===================\n",
      "['He', 'loves', 'his', 'daughter', 'very', 'much', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['he', 'loves', 'his', 'daughter', 'very', 'much', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['He', 'loves', 'daughter', 'much', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['He', 'loves', 'his', 'daughter', 'very', 'much']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['He', 'loves', 'his', 'daughter', 'very', 'much', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['He', 'loves', 'his', 'daughter', 'very', 'much']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['he', 'love', 'hi', 'daughter', 'veri', 'much', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['He', 'love', 'his', 'daughter', 'very', 'much', '.']\n",
      "3.\n",
      "===================NLTK Tokenizer===================\n",
      "['3', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['3 .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "[]\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['3']\n",
      "===================NLTK Tokenizer===================\n",
      "['3', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['3', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['3', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "[]\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['3', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "[]\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['3', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['3', '.']\n",
      "Aforementioned daughter is going to Paris.\n",
      "===================NLTK Tokenizer===================\n",
      "['Aforementioned', 'daughter', 'is', 'going', 'to', 'Paris', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Aforementioned daughter', 'daughter is', 'is going', 'going to', 'to Paris', 'Paris .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Aforementioned daughter is', 'daughter is going', 'is going to', 'going to Paris', 'to Paris .']\n",
      "===================Phrase Machine===================\n",
      "aforementioned daughter\n",
      "===================Rake===================\n",
      "['aforementioned daughter', 'paris', 'going']\n",
      "===================NLTK Tokenizer===================\n",
      "['Aforementioned', 'daughter', 'is', 'going', 'to', 'Paris', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['aforementioned', 'daughter', 'is', 'going', 'to', 'paris', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Aforementioned', 'daughter', 'going', 'Paris', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Aforementioned', 'daughter', 'is', 'going', 'to', 'Paris']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Aforementioned', 'daughter', 'is', 'going', 'to', 'Paris', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Aforementioned', 'daughter', 'is', 'going', 'to', 'Paris']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['aforement', 'daughter', 'is', 'go', 'to', 'pari', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Aforementioned', 'daughter', 'is', 'going', 'to', 'Paris', '.']\n",
      "In order to establish these three facts, which any competent writer or director could do in about ten minutes, the film takes over half an hour, quite possibly the most laborious half an hour in cinematic history.\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'order', 'to', 'establish', 'these', 'three', 'facts', ',', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minutes', ',', 'the', 'film', 'takes', 'over', 'half', 'an', 'hour', ',', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['In order', 'order to', 'to establish', 'establish these', 'these three', 'three facts', 'facts ,', ', which', 'which any', 'any competent', 'competent writer', 'writer or', 'or director', 'director could', 'could do', 'do in', 'in about', 'about ten', 'ten minutes', 'minutes ,', ', the', 'the film', 'film takes', 'takes over', 'over half', 'half an', 'an hour', 'hour ,', ', quite', 'quite possibly', 'possibly the', 'the most', 'most laborious', 'laborious half', 'half an', 'an hour', 'hour in', 'in cinematic', 'cinematic history', 'history .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['In order to', 'order to establish', 'to establish these', 'establish these three', 'these three facts', 'three facts ,', 'facts , which', ', which any', 'which any competent', 'any competent writer', 'competent writer or', 'writer or director', 'or director could', 'director could do', 'could do in', 'do in about', 'in about ten', 'about ten minutes', 'ten minutes ,', 'minutes , the', ', the film', 'the film takes', 'film takes over', 'takes over half', 'over half an', 'half an hour', 'an hour ,', 'hour , quite', ', quite possibly', 'quite possibly the', 'possibly the most', 'the most laborious', 'most laborious half', 'laborious half an', 'half an hour', 'an hour in', 'hour in cinematic', 'in cinematic history', 'cinematic history .']\n",
      "===================Phrase Machine===================\n",
      "three facts\n",
      "competent writer\n",
      "ten minutes\n",
      "hour in cinematic history\n",
      "cinematic history\n",
      "===================Rake===================\n",
      "['three facts', 'ten minutes', 'quite possibly', 'film takes', 'director could', 'competent writer', 'cinematic history', 'laborious half', 'half', 'order', 'hour', 'hour', 'establish']\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'order', 'to', 'establish', 'these', 'three', 'facts', ',', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minutes', ',', 'the', 'film', 'takes', 'over', 'half', 'an', 'hour', ',', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['in', 'order', 'to', 'establish', 'these', 'three', 'facts', ',', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minutes', ',', 'the', 'film', 'takes', 'over', 'half', 'an', 'hour', ',', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['In', 'order', 'establish', 'three', 'facts', ',', 'competent', 'writer', 'director', 'could', 'ten', 'minutes', ',', 'film', 'takes', 'half', 'hour', ',', 'quite', 'possibly', 'laborious', 'half', 'hour', 'cinematic', 'history', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['In', 'order', 'to', 'establish', 'these', 'three', 'facts', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minutes', 'the', 'film', 'takes', 'over', 'half', 'an', 'hour', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['In', 'order', 'to', 'establish', 'these', 'three', 'facts', ',', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minutes', ',', 'the', 'film', 'takes', 'over', 'half', 'an', 'hour', ',', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['In', 'order', 'to', 'establish', 'these', 'three', 'facts', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minutes', 'the', 'film', 'takes', 'over', 'half', 'an', 'hour', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['in', 'order', 'to', 'establish', 'these', 'three', 'fact', ',', 'which', 'ani', 'compet', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minut', ',', 'the', 'film', 'take', 'over', 'half', 'an', 'hour', ',', 'quit', 'possibl', 'the', 'most', 'labori', 'half', 'an', 'hour', 'in', 'cinemat', 'histori', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['In', 'order', 'to', 'establish', 'these', 'three', 'fact', ',', 'which', 'any', 'competent', 'writer', 'or', 'director', 'could', 'do', 'in', 'about', 'ten', 'minute', ',', 'the', 'film', 'take', 'over', 'half', 'an', 'hour', ',', 'quite', 'possibly', 'the', 'most', 'laborious', 'half', 'an', 'hour', 'in', 'cinematic', 'history', '.']\n",
      "As soon as the daughter reaches Paris, she is of course kidnapped.\n",
      "===================NLTK Tokenizer===================\n",
      "['As', 'soon', 'as', 'the', 'daughter', 'reaches', 'Paris', ',', 'she', 'is', 'of', 'course', 'kidnapped', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['As soon', 'soon as', 'as the', 'the daughter', 'daughter reaches', 'reaches Paris', 'Paris ,', ', she', 'she is', 'is of', 'of course', 'course kidnapped', 'kidnapped .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['As soon as', 'soon as the', 'as the daughter', 'the daughter reaches', 'daughter reaches Paris', 'reaches Paris ,', 'Paris , she', ', she is', 'she is of', 'is of course', 'of course kidnapped', 'course kidnapped .']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['daughter reaches paris', 'course kidnapped', 'soon']\n",
      "===================NLTK Tokenizer===================\n",
      "['As', 'soon', 'as', 'the', 'daughter', 'reaches', 'Paris', ',', 'she', 'is', 'of', 'course', 'kidnapped', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['as', 'soon', 'as', 'the', 'daughter', 'reaches', 'paris', ',', 'she', 'is', 'of', 'course', 'kidnapped', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['As', 'soon', 'daughter', 'reaches', 'Paris', ',', 'course', 'kidnapped', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['As', 'soon', 'as', 'the', 'daughter', 'reaches', 'Paris', 'she', 'is', 'of', 'course', 'kidnapped']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['As', 'soon', 'as', 'the', 'daughter', 'reaches', 'Paris', ',', 'she', 'is', 'of', 'course', 'kidnapped', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['As', 'soon', 'as', 'the', 'daughter', 'reaches', 'Paris', 'she', 'is', 'of', 'course', 'kidnapped']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['as', 'soon', 'as', 'the', 'daughter', 'reach', 'pari', ',', 'she', 'is', 'of', 'cours', 'kidnap', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['As', 'soon', 'a', 'the', 'daughter', 'reach', 'Paris', ',', 'she', 'is', 'of', 'course', 'kidnapped', '.']\n",
      "Literally AS SOON.\n",
      "===================NLTK Tokenizer===================\n",
      "['Literally', 'AS', 'SOON', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Literally AS', 'AS SOON', 'SOON .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Literally AS SOON', 'AS SOON .']\n",
      "===================Phrase Machine===================\n",
      "as soon\n",
      "===================Rake===================\n",
      "['soon', 'literally']\n",
      "===================NLTK Tokenizer===================\n",
      "['Literally', 'AS', 'SOON', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['literally', 'as', 'soon', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Literally', 'AS', 'SOON', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Literally', 'AS', 'SOON']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Literally', 'AS', 'SOON', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Literally', 'AS', 'SOON']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['liter', 'as', 'soon', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Literally', 'AS', 'SOON', '.']\n",
      "So there is a sudden escalation in pace that doesn't leave the watcher thinking \"WOW, I didn't see that coming\" or \"Wo, what a skillful escalation in pace\" but simply \"OH Jesus Christ SAVIOUR OF THE WORLD THANK GOD THAT SOMETHING FINALLY HAPPENED!\"\n",
      "===================NLTK Tokenizer===================\n",
      "['So', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'does', \"n't\", 'leave', 'the', 'watcher', 'thinking', '``', 'WOW', ',', 'I', 'did', \"n't\", 'see', 'that', 'coming', \"''\", 'or', '``', 'Wo', ',', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', \"''\", 'but', 'simply', '``', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED', '!', \"''\"]\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['So there', 'there is', 'is a', 'a sudden', 'sudden escalation', 'escalation in', 'in pace', 'pace that', 'that does', \"does n't\", \"n't leave\", 'leave the', 'the watcher', 'watcher thinking', 'thinking ``', '`` WOW', 'WOW ,', ', I', 'I did', \"did n't\", \"n't see\", 'see that', 'that coming', \"coming ''\", \"'' or\", 'or ``', '`` Wo', 'Wo ,', ', what', 'what a', 'a skillful', 'skillful escalation', 'escalation in', 'in pace', \"pace ''\", \"'' but\", 'but simply', 'simply ``', '`` OH', 'OH Jesus', 'Jesus Christ', 'Christ SAVIOUR', 'SAVIOUR OF', 'OF THE', 'THE WORLD', 'WORLD THANK', 'THANK GOD', 'GOD THAT', 'THAT SOMETHING', 'SOMETHING FINALLY', 'FINALLY HAPPENED', 'HAPPENED !', \"! ''\"]\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['So there is', 'there is a', 'is a sudden', 'a sudden escalation', 'sudden escalation in', 'escalation in pace', 'in pace that', 'pace that does', \"that does n't\", \"does n't leave\", \"n't leave the\", 'leave the watcher', 'the watcher thinking', 'watcher thinking ``', 'thinking `` WOW', '`` WOW ,', 'WOW , I', ', I did', \"I did n't\", \"did n't see\", \"n't see that\", 'see that coming', \"that coming ''\", \"coming '' or\", \"'' or ``\", 'or `` Wo', '`` Wo ,', 'Wo , what', ', what a', 'what a skillful', 'a skillful escalation', 'skillful escalation in', 'escalation in pace', \"in pace ''\", \"pace '' but\", \"'' but simply\", 'but simply ``', 'simply `` OH', '`` OH Jesus', 'OH Jesus Christ', 'Jesus Christ SAVIOUR', 'Christ SAVIOUR OF', 'SAVIOUR OF THE', 'OF THE WORLD', 'THE WORLD THANK', 'WORLD THANK GOD', 'THANK GOD THAT', 'GOD THAT SOMETHING', 'THAT SOMETHING FINALLY', 'SOMETHING FINALLY HAPPENED', 'FINALLY HAPPENED !', \"HAPPENED ! ''\"]\n",
      "===================Phrase Machine===================\n",
      "sudden escalation\n",
      "sudden escalation in pace\n",
      "escalation in pace\n",
      "skillful escalation\n",
      "skillful escalation in pace\n",
      "oh jesus\n",
      "oh jesus christ\n",
      "oh jesus christ saviour\n",
      "oh jesus christ saviour of the\n",
      "oh jesus christ saviour of the world\n",
      "oh jesus christ saviour of the world thank\n",
      "jesus christ\n",
      "jesus christ saviour\n",
      "jesus christ saviour of the\n",
      "jesus christ saviour of the world\n",
      "jesus christ saviour of the world thank\n",
      "jesus christ saviour of the world thank god\n",
      "christ saviour\n",
      "christ saviour of the\n",
      "christ saviour of the world\n",
      "christ saviour of the world thank\n",
      "christ saviour of the world thank god\n",
      "christ saviour of the world thank god that\n",
      "saviour of the\n",
      "saviour of the world\n",
      "saviour of the world thank\n",
      "saviour of the world thank god\n",
      "saviour of the world thank god that\n",
      "saviour of the world thank god that something\n",
      "the world\n",
      "the world thank\n",
      "the world thank god\n",
      "the world thank god that\n",
      "the world thank god that something\n",
      "the world thank god that something finally\n",
      "the world thank god that something finally happened\n",
      "world thank\n",
      "world thank god\n",
      "world thank god that\n",
      "world thank god that something\n",
      "world thank god that something finally\n",
      "world thank god that something finally happened\n",
      "thank god\n",
      "thank god that\n",
      "thank god that something\n",
      "thank god that something finally\n",
      "thank god that something finally happened\n",
      "god that\n",
      "god that something\n",
      "god that something finally\n",
      "god that something finally happened\n",
      "that something\n",
      "that something finally\n",
      "that something finally happened\n",
      "something finally\n",
      "something finally happened\n",
      "finally happened\n",
      "===================Rake===================\n",
      "['something finally happened !\"', 'oh jesus christ saviour', 'world thank god', 'watcher thinking', 'sudden escalation', 'skillful escalation', 'wow', 'wo', 'simply', 'see', 'pace', 'pace', 'leave', 'coming']\n",
      "===================NLTK Tokenizer===================\n",
      "['So', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'does', \"n't\", 'leave', 'the', 'watcher', 'thinking', '``', 'WOW', ',', 'I', 'did', \"n't\", 'see', 'that', 'coming', \"''\", 'or', '``', 'Wo', ',', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', \"''\", 'but', 'simply', '``', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED', '!', \"''\"]\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['so', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'does', \"n't\", 'leave', 'the', 'watcher', 'thinking', '``', 'wow', ',', 'i', 'did', \"n't\", 'see', 'that', 'coming', \"''\", 'or', '``', 'wo', ',', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', \"''\", 'but', 'simply', '``', 'oh', 'jesus', 'christ', 'saviour', 'of', 'the', 'world', 'thank', 'god', 'that', 'something', 'finally', 'happened', '!', \"''\"]\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['So', 'sudden', 'escalation', 'pace', \"n't\", 'leave', 'watcher', 'thinking', '``', 'WOW', ',', 'I', \"n't\", 'see', 'coming', \"''\", '``', 'Wo', ',', 'skillful', 'escalation', 'pace', \"''\", 'simply', '``', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED', '!', \"''\"]\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['So', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'doesn', 't', 'leave', 'the', 'watcher', 'thinking', 'WOW', 'I', 'didn', 't', 'see', 'that', 'coming', 'or', 'Wo', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', 'but', 'simply', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['So', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'does', \"n't\", 'leave', 'the', 'watcher', 'thinking', '``', 'WOW', ',', 'I', 'did', \"n't\", 'see', 'that', 'coming', \"''\", 'or', '``', 'Wo', ',', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', \"''\", 'but', 'simply', '``', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED', '!', \"''\"]\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['So', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'doesn', 't', 'leave', 'the', 'watcher', 'thinking', 'WOW', 'I', 'didn', 't', 'see', 'that', 'coming', 'or', 'Wo', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', 'but', 'simply', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['so', 'there', 'is', 'a', 'sudden', 'escal', 'in', 'pace', 'that', 'doe', \"n't\", 'leav', 'the', 'watcher', 'think', '``', 'wow', ',', 'i', 'did', \"n't\", 'see', 'that', 'come', '``', 'or', '``', 'wo', ',', 'what', 'a', 'skill', 'escal', 'in', 'pace', '``', 'but', 'simpli', '``', 'oh', 'jesu', 'christ', 'saviour', 'of', 'the', 'world', 'thank', 'god', 'that', 'someth', 'final', 'happen', '!', '``']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['So', 'there', 'is', 'a', 'sudden', 'escalation', 'in', 'pace', 'that', 'doe', \"n't\", 'leave', 'the', 'watcher', 'thinking', '``', 'WOW', ',', 'I', 'did', \"n't\", 'see', 'that', 'coming', '``', 'or', '``', 'Wo', ',', 'what', 'a', 'skillful', 'escalation', 'in', 'pace', '``', 'but', 'simply', '``', 'OH', 'Jesus', 'Christ', 'SAVIOUR', 'OF', 'THE', 'WORLD', 'THANK', 'GOD', 'THAT', 'SOMETHING', 'FINALLY', 'HAPPENED', '!', '``']\n",
      "This sudden plot \"twist\" of course makes the liberal mother and fat, short stereotypically wealthy stepfather look villainous and the absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help father, who believes his daughter is safer in Los Angeles than Paris, becomes the all-knowing hero.\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'sudden', 'plot', '``', 'twist', \"''\", 'of', 'course', 'makes', 'the', 'liberal', 'mother', 'and', 'fat', ',', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'who', 'believes', 'his', 'daughter', 'is', 'safer', 'in', 'Los', 'Angeles', 'than', 'Paris', ',', 'becomes', 'the', 'all-knowing', 'hero', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['This sudden', 'sudden plot', 'plot ``', '`` twist', \"twist ''\", \"'' of\", 'of course', 'course makes', 'makes the', 'the liberal', 'liberal mother', 'mother and', 'and fat', 'fat ,', ', short', 'short stereotypically', 'stereotypically wealthy', 'wealthy stepfather', 'stepfather look', 'look villainous', 'villainous and', 'and the', 'the absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help father', 'father ,', ', who', 'who believes', 'believes his', 'his daughter', 'daughter is', 'is safer', 'safer in', 'in Los', 'Los Angeles', 'Angeles than', 'than Paris', 'Paris ,', ', becomes', 'becomes the', 'the all-knowing', 'all-knowing hero', 'hero .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['This sudden plot', 'sudden plot ``', 'plot `` twist', \"`` twist ''\", \"twist '' of\", \"'' of course\", 'of course makes', 'course makes the', 'makes the liberal', 'the liberal mother', 'liberal mother and', 'mother and fat', 'and fat ,', 'fat , short', ', short stereotypically', 'short stereotypically wealthy', 'stereotypically wealthy stepfather', 'wealthy stepfather look', 'stepfather look villainous', 'look villainous and', 'villainous and the', 'and the absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'the absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help father', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help father ,', 'father , who', ', who believes', 'who believes his', 'believes his daughter', 'his daughter is', 'daughter is safer', 'is safer in', 'safer in Los', 'in Los Angeles', 'Los Angeles than', 'Angeles than Paris', 'than Paris ,', 'Paris , becomes', ', becomes the', 'becomes the all-knowing', 'the all-knowing hero', 'all-knowing hero .']\n",
      "===================Phrase Machine===================\n",
      "sudden plot\n",
      "liberal mother\n",
      "wealthy stepfather\n",
      "wealthy stepfather look\n",
      "stepfather look\n",
      "absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help father\n",
      "los angeles\n",
      "los angeles than paris\n",
      "angeles than paris\n",
      "all-knowing hero\n",
      "===================Rake===================\n",
      "['short stereotypically wealthy stepfather look villainous', 'sudden plot', 'los angeles', 'liberal mother', 'knowing hero', 'help father', 'course makes', 'twist', 'seek', 'safer', 'professional', 'paris', 'paranoid', 'fat', 'degree', 'daughter', 'believes', 'becomes', 'absurdly']\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'sudden', 'plot', '``', 'twist', \"''\", 'of', 'course', 'makes', 'the', 'liberal', 'mother', 'and', 'fat', ',', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'who', 'believes', 'his', 'daughter', 'is', 'safer', 'in', 'Los', 'Angeles', 'than', 'Paris', ',', 'becomes', 'the', 'all-knowing', 'hero', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['this', 'sudden', 'plot', '``', 'twist', \"''\", 'of', 'course', 'makes', 'the', 'liberal', 'mother', 'and', 'fat', ',', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'who', 'believes', 'his', 'daughter', 'is', 'safer', 'in', 'los', 'angeles', 'than', 'paris', ',', 'becomes', 'the', 'all-knowing', 'hero', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['This', 'sudden', 'plot', '``', 'twist', \"''\", 'course', 'makes', 'liberal', 'mother', 'fat', ',', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'believes', 'daughter', 'safer', 'Los', 'Angeles', 'Paris', ',', 'becomes', 'all-knowing', 'hero', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['This', 'sudden', 'plot', 'twist', 'of', 'course', 'makes', 'the', 'liberal', 'mother', 'and', 'fat', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly', 'paranoid', 'to', 'the', 'degree', 'that', 'he', 'should', 'seek', 'professional', 'help', 'father', 'who', 'believes', 'his', 'daughter', 'is', 'safer', 'in', 'Los', 'Angeles', 'than', 'Paris', 'becomes', 'the', 'all', 'knowing', 'hero']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['This', 'sudden', 'plot', '``', 'twist', \"''\", 'of', 'course', 'makes', 'the', 'liberal', 'mother', 'and', 'fat', ',', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'who', 'believes', 'his', 'daughter', 'is', 'safer', 'in', 'Los', 'Angeles', 'than', 'Paris', ',', 'becomes', 'the', 'all-knowing', 'hero', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['This', 'sudden', 'plot', 'twist', 'of', 'course', 'makes', 'the', 'liberal', 'mother', 'and', 'fat', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly', 'paranoid', 'to', 'the', 'degree', 'that', 'he', 'should', 'seek', 'professional', 'help', 'father', 'who', 'believes', 'his', 'daughter', 'is', 'safer', 'in', 'Los', 'Angeles', 'than', 'Paris', 'becomes', 'the', 'all', 'knowing', 'hero']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['thi', 'sudden', 'plot', '``', 'twist', '``', 'of', 'cours', 'make', 'the', 'liber', 'mother', 'and', 'fat', ',', 'short', 'stereotyp', 'wealthi', 'stepfath', 'look', 'villain', 'and', 'the', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'who', 'believ', 'hi', 'daughter', 'is', 'safer', 'in', 'lo', 'angel', 'than', 'pari', ',', 'becom', 'the', 'all-know', 'hero', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['This', 'sudden', 'plot', '``', 'twist', '``', 'of', 'course', 'make', 'the', 'liberal', 'mother', 'and', 'fat', ',', 'short', 'stereotypically', 'wealthy', 'stepfather', 'look', 'villainous', 'and', 'the', 'absurdly-paranoid-to-the-degree-that-he-should-seek-professional-help', 'father', ',', 'who', 'belief', 'his', 'daughter', 'is', 'safer', 'in', 'Los', 'Angeles', 'than', 'Paris', ',', 'becomes', 'the', 'all-knowing', 'hero', '.']\n",
      "And of course the CIA can detect from a tiny and poor-quality voice sample the hometown of any speaker.\n",
      "===================NLTK Tokenizer===================\n",
      "['And', 'of', 'course', 'the', 'CIA', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor-quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['And of', 'of course', 'course the', 'the CIA', 'CIA can', 'can detect', 'detect from', 'from a', 'a tiny', 'tiny and', 'and poor-quality', 'poor-quality voice', 'voice sample', 'sample the', 'the hometown', 'hometown of', 'of any', 'any speaker', 'speaker .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['And of course', 'of course the', 'course the CIA', 'the CIA can', 'CIA can detect', 'can detect from', 'detect from a', 'from a tiny', 'a tiny and', 'tiny and poor-quality', 'and poor-quality voice', 'poor-quality voice sample', 'voice sample the', 'sample the hometown', 'the hometown of', 'hometown of any', 'of any speaker', 'any speaker .']\n",
      "===================Phrase Machine===================\n",
      "poor-quality voice\n",
      "hometown of any speaker\n",
      "===================Rake===================\n",
      "['quality voice sample', 'tiny', 'speaker', 'poor', 'hometown', 'detect', 'course', 'cia']\n",
      "===================NLTK Tokenizer===================\n",
      "['And', 'of', 'course', 'the', 'CIA', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor-quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['and', 'of', 'course', 'the', 'cia', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor-quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['And', 'course', 'CIA', 'detect', 'tiny', 'poor-quality', 'voice', 'sample', 'hometown', 'speaker', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['And', 'of', 'course', 'the', 'CIA', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor', 'quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['And', 'of', 'course', 'the', 'CIA', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor-quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['And', 'of', 'course', 'the', 'CIA', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor', 'quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['and', 'of', 'cours', 'the', 'cia', 'can', 'detect', 'from', 'a', 'tini', 'and', 'poor-qual', 'voic', 'sampl', 'the', 'hometown', 'of', 'ani', 'speaker', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['And', 'of', 'course', 'the', 'CIA', 'can', 'detect', 'from', 'a', 'tiny', 'and', 'poor-quality', 'voice', 'sample', 'the', 'hometown', 'of', 'any', 'speaker', '.']\n",
      "So we learn that the daughter has been kidnapped by an Albanian gang who intend to sell her into sex slavery.\n",
      "===================NLTK Tokenizer===================\n",
      "['So', 'we', 'learn', 'that', 'the', 'daughter', 'has', 'been', 'kidnapped', 'by', 'an', 'Albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['So we', 'we learn', 'learn that', 'that the', 'the daughter', 'daughter has', 'has been', 'been kidnapped', 'kidnapped by', 'by an', 'an Albanian', 'Albanian gang', 'gang who', 'who intend', 'intend to', 'to sell', 'sell her', 'her into', 'into sex', 'sex slavery', 'slavery .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['So we learn', 'we learn that', 'learn that the', 'that the daughter', 'the daughter has', 'daughter has been', 'has been kidnapped', 'been kidnapped by', 'kidnapped by an', 'by an Albanian', 'an Albanian gang', 'Albanian gang who', 'gang who intend', 'who intend to', 'intend to sell', 'to sell her', 'sell her into', 'her into sex', 'into sex slavery', 'sex slavery .']\n",
      "===================Phrase Machine===================\n",
      "albanian gang\n",
      "sex slavery\n",
      "===================Rake===================\n",
      "['sex slavery', 'albanian gang', 'sell', 'learn', 'kidnapped', 'intend', 'daughter']\n",
      "===================NLTK Tokenizer===================\n",
      "['So', 'we', 'learn', 'that', 'the', 'daughter', 'has', 'been', 'kidnapped', 'by', 'an', 'Albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['so', 'we', 'learn', 'that', 'the', 'daughter', 'has', 'been', 'kidnapped', 'by', 'an', 'albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['So', 'learn', 'daughter', 'kidnapped', 'Albanian', 'gang', 'intend', 'sell', 'sex', 'slavery', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['So', 'we', 'learn', 'that', 'the', 'daughter', 'has', 'been', 'kidnapped', 'by', 'an', 'Albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['So', 'we', 'learn', 'that', 'the', 'daughter', 'has', 'been', 'kidnapped', 'by', 'an', 'Albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['So', 'we', 'learn', 'that', 'the', 'daughter', 'has', 'been', 'kidnapped', 'by', 'an', 'Albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['so', 'we', 'learn', 'that', 'the', 'daughter', 'ha', 'been', 'kidnap', 'by', 'an', 'albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slaveri', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['So', 'we', 'learn', 'that', 'the', 'daughter', 'ha', 'been', 'kidnapped', 'by', 'an', 'Albanian', 'gang', 'who', 'intend', 'to', 'sell', 'her', 'into', 'sex', 'slavery', '.']\n",
      "This is of course the point where the film ceases to be just bad and becomes outright immoral: people trafficking with the intent of prostitution is a real and tangible problem in Europe and indeed all over the world (if you want to see an actually worthy film that deals with the issue I suggest \"Eastern Promises\", \"Dirty Pretty Things\" or \"Spare Parts\").\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'ceases', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', ':', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'Europe', 'and', 'indeed', 'all', 'over', 'the', 'world', '(', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deals', 'with', 'the', 'issue', 'I', 'suggest', '``', 'Eastern', 'Promises', \"''\", ',', '``', 'Dirty', 'Pretty', 'Things', \"''\", 'or', '``', 'Spare', 'Parts', \"''\", ')', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['This is', 'is of', 'of course', 'course the', 'the point', 'point where', 'where the', 'the film', 'film ceases', 'ceases to', 'to be', 'be just', 'just bad', 'bad and', 'and becomes', 'becomes outright', 'outright immoral', 'immoral :', ': people', 'people trafficking', 'trafficking with', 'with the', 'the intent', 'intent of', 'of prostitution', 'prostitution is', 'is a', 'a real', 'real and', 'and tangible', 'tangible problem', 'problem in', 'in Europe', 'Europe and', 'and indeed', 'indeed all', 'all over', 'over the', 'the world', 'world (', '( if', 'if you', 'you want', 'want to', 'to see', 'see an', 'an actually', 'actually worthy', 'worthy film', 'film that', 'that deals', 'deals with', 'with the', 'the issue', 'issue I', 'I suggest', 'suggest ``', '`` Eastern', 'Eastern Promises', \"Promises ''\", \"'' ,\", ', ``', '`` Dirty', 'Dirty Pretty', 'Pretty Things', \"Things ''\", \"'' or\", 'or ``', '`` Spare', 'Spare Parts', \"Parts ''\", \"'' )\", ') .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['This is of', 'is of course', 'of course the', 'course the point', 'the point where', 'point where the', 'where the film', 'the film ceases', 'film ceases to', 'ceases to be', 'to be just', 'be just bad', 'just bad and', 'bad and becomes', 'and becomes outright', 'becomes outright immoral', 'outright immoral :', 'immoral : people', ': people trafficking', 'people trafficking with', 'trafficking with the', 'with the intent', 'the intent of', 'intent of prostitution', 'of prostitution is', 'prostitution is a', 'is a real', 'a real and', 'real and tangible', 'and tangible problem', 'tangible problem in', 'problem in Europe', 'in Europe and', 'Europe and indeed', 'and indeed all', 'indeed all over', 'all over the', 'over the world', 'the world (', 'world ( if', '( if you', 'if you want', 'you want to', 'want to see', 'to see an', 'see an actually', 'an actually worthy', 'actually worthy film', 'worthy film that', 'film that deals', 'that deals with', 'deals with the', 'with the issue', 'the issue I', 'issue I suggest', 'I suggest ``', 'suggest `` Eastern', '`` Eastern Promises', \"Eastern Promises ''\", \"Promises '' ,\", \"'' , ``\", ', `` Dirty', '`` Dirty Pretty', 'Dirty Pretty Things', \"Pretty Things ''\", \"Things '' or\", \"'' or ``\", 'or `` Spare', '`` Spare Parts', \"Spare Parts ''\", \"Parts '' )\", \"'' ) .\"]\n",
      "===================Phrase Machine===================\n",
      "intent of prostitution\n",
      "tangible problem\n",
      "tangible problem in europe\n",
      "problem in europe\n",
      "worthy film\n",
      "worthy film that deals\n",
      "worthy film that deals with the issue\n",
      "film that deals\n",
      "film that deals with the issue\n",
      "deals with the issue\n",
      "eastern promises\n",
      "dirty pretty\n",
      "dirty pretty things\n",
      "pretty things\n",
      "spare parts\n",
      "===================Rake===================\n",
      "['spare parts \").', 'eastern promises \",', 'dirty pretty things', 'becomes outright immoral', 'actually worthy film', 'film ceases', 'tangible problem', 'people trafficking', 'world', 'want', 'suggest', 'see', 'real', 'prostitution', 'point', 'issue', 'intent', 'indeed', 'europe', 'deals', 'course', 'bad']\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'ceases', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', ':', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'Europe', 'and', 'indeed', 'all', 'over', 'the', 'world', '(', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deals', 'with', 'the', 'issue', 'I', 'suggest', '``', 'Eastern', 'Promises', \"''\", ',', '``', 'Dirty', 'Pretty', 'Things', \"''\", 'or', '``', 'Spare', 'Parts', \"''\", ')', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['this', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'ceases', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', ':', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'europe', 'and', 'indeed', 'all', 'over', 'the', 'world', '(', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deals', 'with', 'the', 'issue', 'i', 'suggest', '``', 'eastern', 'promises', \"''\", ',', '``', 'dirty', 'pretty', 'things', \"''\", 'or', '``', 'spare', 'parts', \"''\", ')', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['This', 'course', 'point', 'film', 'ceases', 'bad', 'becomes', 'outright', 'immoral', ':', 'people', 'trafficking', 'intent', 'prostitution', 'real', 'tangible', 'problem', 'Europe', 'indeed', 'world', '(', 'want', 'see', 'actually', 'worthy', 'film', 'deals', 'issue', 'I', 'suggest', '``', 'Eastern', 'Promises', \"''\", ',', '``', 'Dirty', 'Pretty', 'Things', \"''\", '``', 'Spare', 'Parts', \"''\", ')', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['This', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'ceases', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'Europe', 'and', 'indeed', 'all', 'over', 'the', 'world', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deals', 'with', 'the', 'issue', 'I', 'suggest', 'Eastern', 'Promises', 'Dirty', 'Pretty', 'Things', 'or', 'Spare', 'Parts']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['This', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'ceases', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', ':', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'Europe', 'and', 'indeed', 'all', 'over', 'the', 'world', '(', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deals', 'with', 'the', 'issue', 'I', 'suggest', '``', 'Eastern', 'Promises', \"''\", ',', '``', 'Dirty', 'Pretty', 'Things', \"''\", 'or', '``', 'Spare', 'Parts', \"''\", ')', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['This', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'ceases', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'Europe', 'and', 'indeed', 'all', 'over', 'the', 'world', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deals', 'with', 'the', 'issue', 'I', 'suggest', 'Eastern', 'Promises', 'Dirty', 'Pretty', 'Things', 'or', 'Spare', 'Parts']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['thi', 'is', 'of', 'cours', 'the', 'point', 'where', 'the', 'film', 'ceas', 'to', 'be', 'just', 'bad', 'and', 'becom', 'outright', 'immor', ':', 'peopl', 'traffick', 'with', 'the', 'intent', 'of', 'prostitut', 'is', 'a', 'real', 'and', 'tangibl', 'problem', 'in', 'europ', 'and', 'inde', 'all', 'over', 'the', 'world', '(', 'if', 'you', 'want', 'to', 'see', 'an', 'actual', 'worthi', 'film', 'that', 'deal', 'with', 'the', 'issu', 'i', 'suggest', '``', 'eastern', 'promis', '``', ',', '``', 'dirti', 'pretti', 'thing', '``', 'or', '``', 'spare', 'part', '``', ')', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['This', 'is', 'of', 'course', 'the', 'point', 'where', 'the', 'film', 'cease', 'to', 'be', 'just', 'bad', 'and', 'becomes', 'outright', 'immoral', ':', 'people', 'trafficking', 'with', 'the', 'intent', 'of', 'prostitution', 'is', 'a', 'real', 'and', 'tangible', 'problem', 'in', 'Europe', 'and', 'indeed', 'all', 'over', 'the', 'world', '(', 'if', 'you', 'want', 'to', 'see', 'an', 'actually', 'worthy', 'film', 'that', 'deal', 'with', 'the', 'issue', 'I', 'suggest', '``', 'Eastern', 'Promises', '``', ',', '``', 'Dirty', 'Pretty', 'Things', '``', 'or', '``', 'Spare', 'Parts', '``', ')', '.']\n",
      "Making it the subject of a Hollywood action film in which the American hero overcomes all the odds to rescue his daughter is insulting to those women who have actually been in this situation.\n",
      "===================NLTK Tokenizer===================\n",
      "['Making', 'it', 'the', 'subject', 'of', 'a', 'Hollywood', 'action', 'film', 'in', 'which', 'the', 'American', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'women', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Making it', 'it the', 'the subject', 'subject of', 'of a', 'a Hollywood', 'Hollywood action', 'action film', 'film in', 'in which', 'which the', 'the American', 'American hero', 'hero overcomes', 'overcomes all', 'all the', 'the odds', 'odds to', 'to rescue', 'rescue his', 'his daughter', 'daughter is', 'is insulting', 'insulting to', 'to those', 'those women', 'women who', 'who have', 'have actually', 'actually been', 'been in', 'in this', 'this situation', 'situation .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Making it the', 'it the subject', 'the subject of', 'subject of a', 'of a Hollywood', 'a Hollywood action', 'Hollywood action film', 'action film in', 'film in which', 'in which the', 'which the American', 'the American hero', 'American hero overcomes', 'hero overcomes all', 'overcomes all the', 'all the odds', 'the odds to', 'odds to rescue', 'to rescue his', 'rescue his daughter', 'his daughter is', 'daughter is insulting', 'is insulting to', 'insulting to those', 'to those women', 'those women who', 'women who have', 'who have actually', 'have actually been', 'actually been in', 'been in this', 'in this situation', 'this situation .']\n",
      "===================Phrase Machine===================\n",
      "subject of a hollywood\n",
      "subject of a hollywood action\n",
      "subject of a hollywood action film\n",
      "hollywood action\n",
      "hollywood action film\n",
      "action film\n",
      "american hero\n",
      "===================Rake===================\n",
      "['hollywood action film', 'american hero overcomes', 'women', 'subject', 'situation', 'rescue', 'odds', 'making', 'insulting', 'daughter', 'actually']\n",
      "===================NLTK Tokenizer===================\n",
      "['Making', 'it', 'the', 'subject', 'of', 'a', 'Hollywood', 'action', 'film', 'in', 'which', 'the', 'American', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'women', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['making', 'it', 'the', 'subject', 'of', 'a', 'hollywood', 'action', 'film', 'in', 'which', 'the', 'american', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'women', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Making', 'subject', 'Hollywood', 'action', 'film', 'American', 'hero', 'overcomes', 'odds', 'rescue', 'daughter', 'insulting', 'women', 'actually', 'situation', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Making', 'it', 'the', 'subject', 'of', 'a', 'Hollywood', 'action', 'film', 'in', 'which', 'the', 'American', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'women', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Making', 'it', 'the', 'subject', 'of', 'a', 'Hollywood', 'action', 'film', 'in', 'which', 'the', 'American', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'women', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Making', 'it', 'the', 'subject', 'of', 'a', 'Hollywood', 'action', 'film', 'in', 'which', 'the', 'American', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'women', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['make', 'it', 'the', 'subject', 'of', 'a', 'hollywood', 'action', 'film', 'in', 'which', 'the', 'american', 'hero', 'overcom', 'all', 'the', 'odd', 'to', 'rescu', 'hi', 'daughter', 'is', 'insult', 'to', 'those', 'women', 'who', 'have', 'actual', 'been', 'in', 'thi', 'situat', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Making', 'it', 'the', 'subject', 'of', 'a', 'Hollywood', 'action', 'film', 'in', 'which', 'the', 'American', 'hero', 'overcomes', 'all', 'the', 'odds', 'to', 'rescue', 'his', 'daughter', 'is', 'insulting', 'to', 'those', 'woman', 'who', 'have', 'actually', 'been', 'in', 'this', 'situation', '.']\n",
      "Particularly appalling is the scant disregard that our \"hero\" shows for the wellbeing of any of the other women.\n",
      "===================NLTK Tokenizer===================\n",
      "['Particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', '``', 'hero', \"''\", 'shows', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'women', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Particularly appalling', 'appalling is', 'is the', 'the scant', 'scant disregard', 'disregard that', 'that our', 'our ``', '`` hero', \"hero ''\", \"'' shows\", 'shows for', 'for the', 'the wellbeing', 'wellbeing of', 'of any', 'any of', 'of the', 'the other', 'other women', 'women .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Particularly appalling is', 'appalling is the', 'is the scant', 'the scant disregard', 'scant disregard that', 'disregard that our', 'that our ``', 'our `` hero', \"`` hero ''\", \"hero '' shows\", \"'' shows for\", 'shows for the', 'for the wellbeing', 'the wellbeing of', 'wellbeing of any', 'of any of', 'any of the', 'of the other', 'the other women', 'other women .']\n",
      "===================Phrase Machine===================\n",
      "scant disregard\n",
      "shows for the wellbeing\n",
      "other women\n",
      "===================Rake===================\n",
      "['scant disregard', 'particularly appalling', 'women', 'wellbeing', 'shows', 'hero']\n",
      "===================NLTK Tokenizer===================\n",
      "['Particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', '``', 'hero', \"''\", 'shows', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'women', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', '``', 'hero', \"''\", 'shows', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'women', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Particularly', 'appalling', 'scant', 'disregard', '``', 'hero', \"''\", 'shows', 'wellbeing', 'women', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', 'hero', 'shows', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'women']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', '``', 'hero', \"''\", 'shows', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'women', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', 'hero', 'shows', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'women']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['particularli', 'appal', 'is', 'the', 'scant', 'disregard', 'that', 'our', '``', 'hero', '``', 'show', 'for', 'the', 'wellb', 'of', 'ani', 'of', 'the', 'other', 'women', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Particularly', 'appalling', 'is', 'the', 'scant', 'disregard', 'that', 'our', '``', 'hero', '``', 'show', 'for', 'the', 'wellbeing', 'of', 'any', 'of', 'the', 'other', 'woman', '.']\n",
      "It left me questioning \"is it supposed to be ironic?\n",
      "===================NLTK Tokenizer===================\n",
      "['It', 'left', 'me', 'questioning', '``', 'is', 'it', 'supposed', 'to', 'be', 'ironic', '?']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['It left', 'left me', 'me questioning', 'questioning ``', '`` is', 'is it', 'it supposed', 'supposed to', 'to be', 'be ironic', 'ironic ?']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['It left me', 'left me questioning', 'me questioning ``', 'questioning `` is', '`` is it', 'is it supposed', 'it supposed to', 'supposed to be', 'to be ironic', 'be ironic ?']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['supposed', 'questioning', 'left', 'ironic']\n",
      "===================NLTK Tokenizer===================\n",
      "['It', 'left', 'me', 'questioning', '``', 'is', 'it', 'supposed', 'to', 'be', 'ironic', '?']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['it', 'left', 'me', 'questioning', '``', 'is', 'it', 'supposed', 'to', 'be', 'ironic', '?']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['It', 'left', 'questioning', '``', 'supposed', 'ironic', '?']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['It', 'left', 'me', 'questioning', 'is', 'it', 'supposed', 'to', 'be', 'ironic']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['It', 'left', 'me', 'questioning', '``', 'is', 'it', 'supposed', 'to', 'be', 'ironic', '?']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['It', 'left', 'me', 'questioning', 'is', 'it', 'supposed', 'to', 'be', 'ironic']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['it', 'left', 'me', 'question', '``', 'is', 'it', 'suppos', 'to', 'be', 'iron', '?']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['It', 'left', 'me', 'questioning', '``', 'is', 'it', 'supposed', 'to', 'be', 'ironic', '?']\n",
      "morally ambiguous?\n",
      "===================NLTK Tokenizer===================\n",
      "['morally', 'ambiguous', '?']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['morally ambiguous', 'ambiguous ?']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['morally ambiguous ?']\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['morally ambiguous']\n",
      "===================NLTK Tokenizer===================\n",
      "['morally', 'ambiguous', '?']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['morally', 'ambiguous', '?']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['morally', 'ambiguous', '?']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['morally', 'ambiguous']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['morally', 'ambiguous', '?']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['morally', 'ambiguous']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['moral', 'ambigu', '?']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['morally', 'ambiguous', '?']\n",
      "No, it's just a film that chose a very sensitive and inappropriate subject for a formula-produced action movie.\n",
      "===================NLTK Tokenizer===================\n",
      "['No', ',', 'it', \"'s\", 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula-produced', 'action', 'movie', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['No ,', ', it', \"it 's\", \"'s just\", 'just a', 'a film', 'film that', 'that chose', 'chose a', 'a very', 'very sensitive', 'sensitive and', 'and inappropriate', 'inappropriate subject', 'subject for', 'for a', 'a formula-produced', 'formula-produced action', 'action movie', 'movie .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['No , it', \", it 's\", \"it 's just\", \"'s just a\", 'just a film', 'a film that', 'film that chose', 'that chose a', 'chose a very', 'a very sensitive', 'very sensitive and', 'sensitive and inappropriate', 'and inappropriate subject', 'inappropriate subject for', 'subject for a', 'for a formula-produced', 'a formula-produced action', 'formula-produced action movie', 'action movie .']\n",
      "===================Phrase Machine===================\n",
      "inappropriate subject\n",
      "inappropriate subject for a formula-produced action\n",
      "inappropriate subject for a formula-produced action movie\n",
      "subject for a formula-produced action\n",
      "subject for a formula-produced action movie\n",
      "formula-produced action\n",
      "formula-produced action movie\n",
      "action movie\n",
      "===================Rake===================\n",
      "['produced action movie', 'inappropriate subject', 'sensitive', 'formula', 'film', 'chose']\n",
      "===================NLTK Tokenizer===================\n",
      "['No', ',', 'it', \"'s\", 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula-produced', 'action', 'movie', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['no', ',', 'it', \"'s\", 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula-produced', 'action', 'movie', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['No', ',', \"'s\", 'film', 'chose', 'sensitive', 'inappropriate', 'subject', 'formula-produced', 'action', 'movie', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['No', 'it', 's', 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula', 'produced', 'action', 'movie']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['No', ',', 'it', \"'s\", 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula-produced', 'action', 'movie', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['No', 'it', 's', 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula', 'produced', 'action', 'movie']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['no', ',', 'it', \"'s\", 'just', 'a', 'film', 'that', 'chose', 'a', 'veri', 'sensit', 'and', 'inappropri', 'subject', 'for', 'a', 'formula-produc', 'action', 'movi', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['No', ',', 'it', \"'s\", 'just', 'a', 'film', 'that', 'chose', 'a', 'very', 'sensitive', 'and', 'inappropriate', 'subject', 'for', 'a', 'formula-produced', 'action', 'movie', '.']\n",
      "As the film continues we are given more and more ridiculous scenes that insult our intelligence.\n",
      "===================NLTK Tokenizer===================\n",
      "['As', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scenes', 'that', 'insult', 'our', 'intelligence', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['As the', 'the film', 'film continues', 'continues we', 'we are', 'are given', 'given more', 'more and', 'and more', 'more ridiculous', 'ridiculous scenes', 'scenes that', 'that insult', 'insult our', 'our intelligence', 'intelligence .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['As the film', 'the film continues', 'film continues we', 'continues we are', 'we are given', 'are given more', 'given more and', 'more and more', 'and more ridiculous', 'more ridiculous scenes', 'ridiculous scenes that', 'scenes that insult', 'that insult our', 'insult our intelligence', 'our intelligence .']\n",
      "===================Phrase Machine===================\n",
      "ridiculous scenes\n",
      "===================Rake===================\n",
      "['ridiculous scenes', 'film continues', 'intelligence', 'insult', 'given']\n",
      "===================NLTK Tokenizer===================\n",
      "['As', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scenes', 'that', 'insult', 'our', 'intelligence', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['as', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scenes', 'that', 'insult', 'our', 'intelligence', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['As', 'film', 'continues', 'given', 'ridiculous', 'scenes', 'insult', 'intelligence', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['As', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scenes', 'that', 'insult', 'our', 'intelligence']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['As', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scenes', 'that', 'insult', 'our', 'intelligence', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['As', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scenes', 'that', 'insult', 'our', 'intelligence']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['as', 'the', 'film', 'continu', 'we', 'are', 'given', 'more', 'and', 'more', 'ridicul', 'scene', 'that', 'insult', 'our', 'intellig', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['As', 'the', 'film', 'continues', 'we', 'are', 'given', 'more', 'and', 'more', 'ridiculous', 'scene', 'that', 'insult', 'our', 'intelligence', '.']\n",
      "One particularly stupid oversight comes when the hero walks into a brothel posing as a Parisian police officer and the villains show absolutely no suspicion of his being impostor, despite the fact that he talks exclusively in English.And the most ridiculously appalling scene comes at the very end.\n",
      "===================NLTK Tokenizer===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'comes', 'when', 'the', 'hero', 'walks', 'into', 'a', 'brothel', 'posing', 'as', 'a', 'Parisian', 'police', 'officer', 'and', 'the', 'villains', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', ',', 'despite', 'the', 'fact', 'that', 'he', 'talks', 'exclusively', 'in', 'English.And', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'comes', 'at', 'the', 'very', 'end', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['One particularly', 'particularly stupid', 'stupid oversight', 'oversight comes', 'comes when', 'when the', 'the hero', 'hero walks', 'walks into', 'into a', 'a brothel', 'brothel posing', 'posing as', 'as a', 'a Parisian', 'Parisian police', 'police officer', 'officer and', 'and the', 'the villains', 'villains show', 'show absolutely', 'absolutely no', 'no suspicion', 'suspicion of', 'of his', 'his being', 'being impostor', 'impostor ,', ', despite', 'despite the', 'the fact', 'fact that', 'that he', 'he talks', 'talks exclusively', 'exclusively in', 'in English.And', 'English.And the', 'the most', 'most ridiculously', 'ridiculously appalling', 'appalling scene', 'scene comes', 'comes at', 'at the', 'the very', 'very end', 'end .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['One particularly stupid', 'particularly stupid oversight', 'stupid oversight comes', 'oversight comes when', 'comes when the', 'when the hero', 'the hero walks', 'hero walks into', 'walks into a', 'into a brothel', 'a brothel posing', 'brothel posing as', 'posing as a', 'as a Parisian', 'a Parisian police', 'Parisian police officer', 'police officer and', 'officer and the', 'and the villains', 'the villains show', 'villains show absolutely', 'show absolutely no', 'absolutely no suspicion', 'no suspicion of', 'suspicion of his', 'of his being', 'his being impostor', 'being impostor ,', 'impostor , despite', ', despite the', 'despite the fact', 'the fact that', 'fact that he', 'that he talks', 'he talks exclusively', 'talks exclusively in', 'exclusively in English.And', 'in English.And the', 'English.And the most', 'the most ridiculously', 'most ridiculously appalling', 'ridiculously appalling scene', 'appalling scene comes', 'scene comes at', 'comes at the', 'at the very', 'the very end', 'very end .']\n",
      "===================Phrase Machine===================\n",
      "stupid oversight\n",
      "brothel posing\n",
      "brothel posing as a parisian police\n",
      "brothel posing as a parisian police officer\n",
      "posing as a parisian police\n",
      "posing as a parisian police officer\n",
      "parisian police\n",
      "parisian police officer\n",
      "police officer\n",
      "appalling scene\n",
      "===================Rake===================\n",
      "['one particularly stupid oversight comes', 'ridiculously appalling scene comes', 'villains show absolutely', 'parisian police officer', 'talks exclusively', 'hero walks', 'brothel posing', 'suspicion', 'impostor', 'fact', 'english', 'end', 'despite']\n",
      "===================NLTK Tokenizer===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'comes', 'when', 'the', 'hero', 'walks', 'into', 'a', 'brothel', 'posing', 'as', 'a', 'Parisian', 'police', 'officer', 'and', 'the', 'villains', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', ',', 'despite', 'the', 'fact', 'that', 'he', 'talks', 'exclusively', 'in', 'English.And', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'comes', 'at', 'the', 'very', 'end', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['one', 'particularly', 'stupid', 'oversight', 'comes', 'when', 'the', 'hero', 'walks', 'into', 'a', 'brothel', 'posing', 'as', 'a', 'parisian', 'police', 'officer', 'and', 'the', 'villains', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', ',', 'despite', 'the', 'fact', 'that', 'he', 'talks', 'exclusively', 'in', 'english.and', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'comes', 'at', 'the', 'very', 'end', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'comes', 'hero', 'walks', 'brothel', 'posing', 'Parisian', 'police', 'officer', 'villains', 'show', 'absolutely', 'suspicion', 'impostor', ',', 'despite', 'fact', 'talks', 'exclusively', 'English.And', 'ridiculously', 'appalling', 'scene', 'comes', 'end', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'comes', 'when', 'the', 'hero', 'walks', 'into', 'a', 'brothel', 'posing', 'as', 'a', 'Parisian', 'police', 'officer', 'and', 'the', 'villains', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', 'despite', 'the', 'fact', 'that', 'he', 'talks', 'exclusively', 'in', 'English', 'And', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'comes', 'at', 'the', 'very', 'end']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'comes', 'when', 'the', 'hero', 'walks', 'into', 'a', 'brothel', 'posing', 'as', 'a', 'Parisian', 'police', 'officer', 'and', 'the', 'villains', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', ',', 'despite', 'the', 'fact', 'that', 'he', 'talks', 'exclusively', 'in', 'English.And', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'comes', 'at', 'the', 'very', 'end', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'comes', 'when', 'the', 'hero', 'walks', 'into', 'a', 'brothel', 'posing', 'as', 'a', 'Parisian', 'police', 'officer', 'and', 'the', 'villains', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', 'despite', 'the', 'fact', 'that', 'he', 'talks', 'exclusively', 'in', 'English', 'And', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'comes', 'at', 'the', 'very', 'end']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['one', 'particularli', 'stupid', 'oversight', 'come', 'when', 'the', 'hero', 'walk', 'into', 'a', 'brothel', 'pose', 'as', 'a', 'parisian', 'polic', 'offic', 'and', 'the', 'villain', 'show', 'absolut', 'no', 'suspicion', 'of', 'hi', 'be', 'impostor', ',', 'despit', 'the', 'fact', 'that', 'he', 'talk', 'exclus', 'in', 'english.and', 'the', 'most', 'ridicul', 'appal', 'scene', 'come', 'at', 'the', 'veri', 'end', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['One', 'particularly', 'stupid', 'oversight', 'come', 'when', 'the', 'hero', 'walk', 'into', 'a', 'brothel', 'posing', 'a', 'a', 'Parisian', 'police', 'officer', 'and', 'the', 'villain', 'show', 'absolutely', 'no', 'suspicion', 'of', 'his', 'being', 'impostor', ',', 'despite', 'the', 'fact', 'that', 'he', 'talk', 'exclusively', 'in', 'English.And', 'the', 'most', 'ridiculously', 'appalling', 'scene', 'come', 'at', 'the', 'very', 'end', '.']\n",
      "The girl is safe as she returns from Paris to Los Angeles.\n",
      "===================NLTK Tokenizer===================\n",
      "['The', 'girl', 'is', 'safe', 'as', 'she', 'returns', 'from', 'Paris', 'to', 'Los', 'Angeles', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['The girl', 'girl is', 'is safe', 'safe as', 'as she', 'she returns', 'returns from', 'from Paris', 'Paris to', 'to Los', 'Los Angeles', 'Angeles .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['The girl is', 'girl is safe', 'is safe as', 'safe as she', 'as she returns', 'she returns from', 'returns from Paris', 'from Paris to', 'Paris to Los', 'to Los Angeles', 'Los Angeles .']\n",
      "===================Phrase Machine===================\n",
      "paris to los\n",
      "paris to los angeles\n",
      "los angeles\n",
      "===================Rake===================\n",
      "['los angeles', 'safe', 'returns', 'paris', 'girl']\n",
      "===================NLTK Tokenizer===================\n",
      "['The', 'girl', 'is', 'safe', 'as', 'she', 'returns', 'from', 'Paris', 'to', 'Los', 'Angeles', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['the', 'girl', 'is', 'safe', 'as', 'she', 'returns', 'from', 'paris', 'to', 'los', 'angeles', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['The', 'girl', 'safe', 'returns', 'Paris', 'Los', 'Angeles', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['The', 'girl', 'is', 'safe', 'as', 'she', 'returns', 'from', 'Paris', 'to', 'Los', 'Angeles']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['The', 'girl', 'is', 'safe', 'as', 'she', 'returns', 'from', 'Paris', 'to', 'Los', 'Angeles', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['The', 'girl', 'is', 'safe', 'as', 'she', 'returns', 'from', 'Paris', 'to', 'Los', 'Angeles']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['the', 'girl', 'is', 'safe', 'as', 'she', 'return', 'from', 'pari', 'to', 'lo', 'angel', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['The', 'girl', 'is', 'safe', 'a', 'she', 'return', 'from', 'Paris', 'to', 'Los', 'Angeles', '.']\n",
      "Finally, back in America, where everyone's safe!\n",
      "===================NLTK Tokenizer===================\n",
      "['Finally', ',', 'back', 'in', 'America', ',', 'where', 'everyone', \"'s\", 'safe', '!']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Finally ,', ', back', 'back in', 'in America', 'America ,', ', where', 'where everyone', \"everyone 's\", \"'s safe\", 'safe !']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Finally , back', ', back in', 'back in America', 'in America ,', 'America , where', ', where everyone', \"where everyone 's\", \"everyone 's safe\", \"'s safe !\"]\n",
      "===================Phrase Machine===================\n",
      "===================Rake===================\n",
      "['safe', 'finally', 'everyone', 'back', 'america']\n",
      "===================NLTK Tokenizer===================\n",
      "['Finally', ',', 'back', 'in', 'America', ',', 'where', 'everyone', \"'s\", 'safe', '!']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['finally', ',', 'back', 'in', 'america', ',', 'where', 'everyone', \"'s\", 'safe', '!']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Finally', ',', 'back', 'America', ',', 'everyone', \"'s\", 'safe', '!']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Finally', 'back', 'in', 'America', 'where', 'everyone', 's', 'safe']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Finally', ',', 'back', 'in', 'America', ',', 'where', 'everyone', \"'s\", 'safe', '!']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Finally', 'back', 'in', 'America', 'where', 'everyone', 's', 'safe']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['final', ',', 'back', 'in', 'america', ',', 'where', 'everyon', \"'s\", 'safe', '!']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Finally', ',', 'back', 'in', 'America', ',', 'where', 'everyone', \"'s\", 'safe', '!']\n",
      "In spite of murdering and torturing so many people and shooting the wife of a leading Parisian police officer, our hero steps off the plane with absolutely no problems.\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'Parisian', 'police', 'officer', ',', 'our', 'hero', 'steps', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problems', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['In spite', 'spite of', 'of murdering', 'murdering and', 'and torturing', 'torturing so', 'so many', 'many people', 'people and', 'and shooting', 'shooting the', 'the wife', 'wife of', 'of a', 'a leading', 'leading Parisian', 'Parisian police', 'police officer', 'officer ,', ', our', 'our hero', 'hero steps', 'steps off', 'off the', 'the plane', 'plane with', 'with absolutely', 'absolutely no', 'no problems', 'problems .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['In spite of', 'spite of murdering', 'of murdering and', 'murdering and torturing', 'and torturing so', 'torturing so many', 'so many people', 'many people and', 'people and shooting', 'and shooting the', 'shooting the wife', 'the wife of', 'wife of a', 'of a leading', 'a leading Parisian', 'leading Parisian police', 'Parisian police officer', 'police officer ,', 'officer , our', ', our hero', 'our hero steps', 'hero steps off', 'steps off the', 'off the plane', 'the plane with', 'plane with absolutely', 'with absolutely no', 'absolutely no problems', 'no problems .']\n",
      "===================Phrase Machine===================\n",
      "many people\n",
      "parisian police\n",
      "parisian police officer\n",
      "police officer\n",
      "hero steps\n",
      "hero steps off the plane\n",
      "steps off the plane\n",
      "===================Rake===================\n",
      "['leading parisian police officer', 'many people', 'hero steps', 'wife', 'torturing', 'spite', 'shooting', 'problems', 'plane', 'murdering', 'absolutely']\n",
      "===================NLTK Tokenizer===================\n",
      "['In', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'Parisian', 'police', 'officer', ',', 'our', 'hero', 'steps', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problems', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['in', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'parisian', 'police', 'officer', ',', 'our', 'hero', 'steps', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problems', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['In', 'spite', 'murdering', 'torturing', 'many', 'people', 'shooting', 'wife', 'leading', 'Parisian', 'police', 'officer', ',', 'hero', 'steps', 'plane', 'absolutely', 'problems', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['In', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'Parisian', 'police', 'officer', 'our', 'hero', 'steps', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problems']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['In', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'Parisian', 'police', 'officer', ',', 'our', 'hero', 'steps', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problems', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['In', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'Parisian', 'police', 'officer', 'our', 'hero', 'steps', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problems']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['in', 'spite', 'of', 'murder', 'and', 'tortur', 'so', 'mani', 'peopl', 'and', 'shoot', 'the', 'wife', 'of', 'a', 'lead', 'parisian', 'polic', 'offic', ',', 'our', 'hero', 'step', 'off', 'the', 'plane', 'with', 'absolut', 'no', 'problem', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['In', 'spite', 'of', 'murdering', 'and', 'torturing', 'so', 'many', 'people', 'and', 'shooting', 'the', 'wife', 'of', 'a', 'leading', 'Parisian', 'police', 'officer', ',', 'our', 'hero', 'step', 'off', 'the', 'plane', 'with', 'absolutely', 'no', 'problem', '.']\n",
      "Despite her best friend's death and a terrible ordeal, the girl is happy and shows no signs of trauma whatsoever.\n",
      "===================NLTK Tokenizer===================\n",
      "['Despite', 'her', 'best', 'friend', \"'s\", 'death', 'and', 'a', 'terrible', 'ordeal', ',', 'the', 'girl', 'is', 'happy', 'and', 'shows', 'no', 'signs', 'of', 'trauma', 'whatsoever', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['Despite her', 'her best', 'best friend', \"friend 's\", \"'s death\", 'death and', 'and a', 'a terrible', 'terrible ordeal', 'ordeal ,', ', the', 'the girl', 'girl is', 'is happy', 'happy and', 'and shows', 'shows no', 'no signs', 'signs of', 'of trauma', 'trauma whatsoever', 'whatsoever .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['Despite her best', 'her best friend', \"best friend 's\", \"friend 's death\", \"'s death and\", 'death and a', 'and a terrible', 'a terrible ordeal', 'terrible ordeal ,', 'ordeal , the', ', the girl', 'the girl is', 'girl is happy', 'is happy and', 'happy and shows', 'and shows no', 'shows no signs', 'no signs of', 'signs of trauma', 'of trauma whatsoever', 'trauma whatsoever .']\n",
      "===================Phrase Machine===================\n",
      "best friend\n",
      "terrible ordeal\n",
      "signs of trauma\n",
      "signs of trauma whatsoever\n",
      "trauma whatsoever\n",
      "===================Rake===================\n",
      "['trauma whatsoever', 'terrible ordeal', 'best friend', 'signs', 'shows', 'happy', 'girl', 'despite', 'death']\n",
      "===================NLTK Tokenizer===================\n",
      "['Despite', 'her', 'best', 'friend', \"'s\", 'death', 'and', 'a', 'terrible', 'ordeal', ',', 'the', 'girl', 'is', 'happy', 'and', 'shows', 'no', 'signs', 'of', 'trauma', 'whatsoever', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['despite', 'her', 'best', 'friend', \"'s\", 'death', 'and', 'a', 'terrible', 'ordeal', ',', 'the', 'girl', 'is', 'happy', 'and', 'shows', 'no', 'signs', 'of', 'trauma', 'whatsoever', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['Despite', 'best', 'friend', \"'s\", 'death', 'terrible', 'ordeal', ',', 'girl', 'happy', 'shows', 'signs', 'trauma', 'whatsoever', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['Despite', 'her', 'best', 'friend', 's', 'death', 'and', 'a', 'terrible', 'ordeal', 'the', 'girl', 'is', 'happy', 'and', 'shows', 'no', 'signs', 'of', 'trauma', 'whatsoever']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['Despite', 'her', 'best', 'friend', \"'s\", 'death', 'and', 'a', 'terrible', 'ordeal', ',', 'the', 'girl', 'is', 'happy', 'and', 'shows', 'no', 'signs', 'of', 'trauma', 'whatsoever', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['Despite', 'her', 'best', 'friend', 's', 'death', 'and', 'a', 'terrible', 'ordeal', 'the', 'girl', 'is', 'happy', 'and', 'shows', 'no', 'signs', 'of', 'trauma', 'whatsoever']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['despit', 'her', 'best', 'friend', \"'s\", 'death', 'and', 'a', 'terribl', 'ordeal', ',', 'the', 'girl', 'is', 'happi', 'and', 'show', 'no', 'sign', 'of', 'trauma', 'whatsoev', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['Despite', 'her', 'best', 'friend', \"'s\", 'death', 'and', 'a', 'terrible', 'ordeal', ',', 'the', 'girl', 'is', 'happy', 'and', 'show', 'no', 'sign', 'of', 'trauma', 'whatsoever', '.']\n",
      "And in spite of the thousands of women who suffer in sex slavery every day of their lives, a plight which this film does absolutely nothing to enlighten the world on, we are made to believe this is a happy ending.\n",
      "===================NLTK Tokenizer===================\n",
      "['And', 'in', 'spite', 'of', 'the', 'thousands', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'lives', ',', 'a', 'plight', 'which', 'this', 'film', 'does', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', ',', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['And in', 'in spite', 'spite of', 'of the', 'the thousands', 'thousands of', 'of women', 'women who', 'who suffer', 'suffer in', 'in sex', 'sex slavery', 'slavery every', 'every day', 'day of', 'of their', 'their lives', 'lives ,', ', a', 'a plight', 'plight which', 'which this', 'this film', 'film does', 'does absolutely', 'absolutely nothing', 'nothing to', 'to enlighten', 'enlighten the', 'the world', 'world on', 'on ,', ', we', 'we are', 'are made', 'made to', 'to believe', 'believe this', 'this is', 'is a', 'a happy', 'happy ending', 'ending .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['And in spite', 'in spite of', 'spite of the', 'of the thousands', 'the thousands of', 'thousands of women', 'of women who', 'women who suffer', 'who suffer in', 'suffer in sex', 'in sex slavery', 'sex slavery every', 'slavery every day', 'every day of', 'day of their', 'of their lives', 'their lives ,', 'lives , a', ', a plight', 'a plight which', 'plight which this', 'which this film', 'this film does', 'film does absolutely', 'does absolutely nothing', 'absolutely nothing to', 'nothing to enlighten', 'to enlighten the', 'enlighten the world', 'the world on', 'world on ,', 'on , we', ', we are', 'we are made', 'are made to', 'made to believe', 'to believe this', 'believe this is', 'this is a', 'is a happy', 'a happy ending', 'happy ending .']\n",
      "===================Phrase Machine===================\n",
      "spite of the thousands\n",
      "spite of the thousands of women\n",
      "thousands of women\n",
      "sex slavery\n",
      "===================Rake===================\n",
      "['sex slavery every day', 'happy ending', 'absolutely nothing', 'world', 'women', 'thousands', 'suffer', 'spite', 'plight', 'made', 'lives', 'film', 'enlighten', 'believe']\n",
      "===================NLTK Tokenizer===================\n",
      "['And', 'in', 'spite', 'of', 'the', 'thousands', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'lives', ',', 'a', 'plight', 'which', 'this', 'film', 'does', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', ',', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['and', 'in', 'spite', 'of', 'the', 'thousands', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'lives', ',', 'a', 'plight', 'which', 'this', 'film', 'does', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', ',', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['And', 'spite', 'thousands', 'women', 'suffer', 'sex', 'slavery', 'every', 'day', 'lives', ',', 'plight', 'film', 'absolutely', 'nothing', 'enlighten', 'world', ',', 'made', 'believe', 'happy', 'ending', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['And', 'in', 'spite', 'of', 'the', 'thousands', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'lives', 'a', 'plight', 'which', 'this', 'film', 'does', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['And', 'in', 'spite', 'of', 'the', 'thousands', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'lives', ',', 'a', 'plight', 'which', 'this', 'film', 'does', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', ',', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['And', 'in', 'spite', 'of', 'the', 'thousands', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'lives', 'a', 'plight', 'which', 'this', 'film', 'does', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['and', 'in', 'spite', 'of', 'the', 'thousand', 'of', 'women', 'who', 'suffer', 'in', 'sex', 'slaveri', 'everi', 'day', 'of', 'their', 'live', ',', 'a', 'plight', 'which', 'thi', 'film', 'doe', 'absolut', 'noth', 'to', 'enlighten', 'the', 'world', 'on', ',', 'we', 'are', 'made', 'to', 'believ', 'thi', 'is', 'a', 'happi', 'end', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['And', 'in', 'spite', 'of', 'the', 'thousand', 'of', 'woman', 'who', 'suffer', 'in', 'sex', 'slavery', 'every', 'day', 'of', 'their', 'life', ',', 'a', 'plight', 'which', 'this', 'film', 'doe', 'absolutely', 'nothing', 'to', 'enlighten', 'the', 'world', 'on', ',', 'we', 'are', 'made', 'to', 'believe', 'this', 'is', 'a', 'happy', 'ending', '.']\n",
      "This film is an insult to my continent and my intelligence, and a mockery of so many people who suffer in silence.\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', ',', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence', '.']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['This film', 'film is', 'is an', 'an insult', 'insult to', 'to my', 'my continent', 'continent and', 'and my', 'my intelligence', 'intelligence ,', ', and', 'and a', 'a mockery', 'mockery of', 'of so', 'so many', 'many people', 'people who', 'who suffer', 'suffer in', 'in silence', 'silence .']\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "['This film is', 'film is an', 'is an insult', 'an insult to', 'insult to my', 'to my continent', 'my continent and', 'continent and my', 'and my intelligence', 'my intelligence ,', 'intelligence , and', ', and a', 'and a mockery', 'a mockery of', 'mockery of so', 'of so many', 'so many people', 'many people who', 'people who suffer', 'who suffer in', 'suffer in silence', 'in silence .']\n",
      "===================Phrase Machine===================\n",
      "many people\n",
      "===================Rake===================\n",
      "['many people', 'suffer', 'silence', 'mockery', 'intelligence', 'insult', 'film', 'continent']\n",
      "===================NLTK Tokenizer===================\n",
      "['This', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', ',', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence', '.']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['this', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', ',', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence', '.']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['This', 'film', 'insult', 'continent', 'intelligence', ',', 'mockery', 'many', 'people', 'suffer', 'silence', '.']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['This', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['This', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', ',', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence', '.']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['This', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['thi', 'film', 'is', 'an', 'insult', 'to', 'my', 'contin', 'and', 'my', 'intellig', ',', 'and', 'a', 'mockeri', 'of', 'so', 'mani', 'peopl', 'who', 'suffer', 'in', 'silenc', '.']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['This', 'film', 'is', 'an', 'insult', 'to', 'my', 'continent', 'and', 'my', 'intelligence', ',', 'and', 'a', 'mockery', 'of', 'so', 'many', 'people', 'who', 'suffer', 'in', 'silence', '.']\n",
      "But I'm European, so of course, I'm an evil people-trafficker n'all...\n",
      "===================NLTK Tokenizer===================\n",
      "['But', 'I', \"'m\", 'European', ',', 'so', 'of', 'course', ',', 'I', \"'m\", 'an', 'evil', 'people-trafficker', \"n'all\", '...']\n",
      "===================NLTK Word NGRAM Tokenizer 2 words===================\n",
      "['But I', \"I 'm\", \"'m European\", 'European ,', ', so', 'so of', 'of course', 'course ,', ', I', \"I 'm\", \"'m an\", 'an evil', 'evil people-trafficker', \"people-trafficker n'all\", \"n'all ...\"]\n",
      "===================NLTK Word NGRAM Tokenizer 3 words===================\n",
      "[\"But I 'm\", \"I 'm European\", \"'m European ,\", 'European , so', ', so of', 'so of course', 'of course ,', 'course , I', \", I 'm\", \"I 'm an\", \"'m an evil\", 'an evil people-trafficker', \"evil people-trafficker n'all\", \"people-trafficker n'all ...\"]\n",
      "===================Phrase Machine===================\n",
      "evil people-trafficker\n",
      "evil people-trafficker n'all\n",
      "people-trafficker n'all\n",
      "===================Rake===================\n",
      "['trafficker n', 'evil people', 'european', 'course', '...']\n",
      "===================NLTK Tokenizer===================\n",
      "['But', 'I', \"'m\", 'European', ',', 'so', 'of', 'course', ',', 'I', \"'m\", 'an', 'evil', 'people-trafficker', \"n'all\", '...']\n",
      "===================NLTK Tokenizer LOWER CASE===================\n",
      "['but', 'i', \"'m\", 'european', ',', 'so', 'of', 'course', ',', 'i', \"'m\", 'an', 'evil', 'people-trafficker', \"n'all\", '...']\n",
      "===================NLTK Tokenizer REMOVE STOP WORDS===================\n",
      "['But', 'I', \"'m\", 'European', ',', 'course', ',', 'I', \"'m\", 'evil', 'people-trafficker', \"n'all\", '...']\n",
      "===================NLTK Tokenizer REMOVED PUNCTUATION===================\n",
      "['But', 'I', 'm', 'European', 'so', 'of', 'course', 'I', 'm', 'an', 'evil', 'people', 'trafficker', 'n', 'all']\n",
      "===================NLTK Tokenizer REMOVED TAGS===================\n",
      "['But', 'I', \"'m\", 'European', ',', 'so', 'of', 'course', ',', 'I', \"'m\", 'an', 'evil', 'people-trafficker', \"n'all\", '...']\n",
      "===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\n",
      "['But', 'I', 'm', 'European', 'so', 'of', 'course', 'I', 'm', 'an', 'evil', 'people', 'trafficker', 'n', 'all']\n",
      "===================NLTK Tokenizer STEMMING APPLIED===================\n",
      "['but', 'i', \"'m\", 'european', ',', 'so', 'of', 'cours', ',', 'i', \"'m\", 'an', 'evil', 'people-traffick', \"n'all\", '...']\n",
      "===================NLTK Tokenizer LEMMATIZATION APPLIED===================\n",
      "['But', 'I', \"'m\", 'European', ',', 'so', 'of', 'course', ',', 'I', \"'m\", 'an', 'evil', 'people-trafficker', \"n'all\", '...']\n"
     ]
    }
   ],
   "source": [
    "#Explore different extractors and difference preprocessing techniques\n",
    "for sentence in sentences_one:\n",
    "    print(sentence)\n",
    "    print(\"===================NLTK Tokenizer===================\")\n",
    "    print(run_nltk_tokenizer(sentence))\n",
    "    print(\"===================NLTK Word NGRAM Tokenizer 2 words===================\")\n",
    "    print(run_nltk_tokenizer_word_ngrams(sentence,2))\n",
    "    print(\"===================NLTK Word NGRAM Tokenizer 3 words===================\")\n",
    "    print(run_nltk_tokenizer_word_ngrams(sentence,3))\n",
    "    print(\"===================Phrase Machine===================\")\n",
    "    phrases=run_phrase_machine(sentence)\n",
    "    for term in phrases[\"counts\"].keys():\n",
    "        print(term)\n",
    "    print(\"===================Rake===================\")\n",
    "    print(run_rake(sentence))\n",
    "    print(\"===================NLTK Tokenizer===================\")\n",
    "    print(run_nltk_tokenizer((sentence)))\n",
    "    print(\"===================NLTK Tokenizer LOWER CASE===================\")\n",
    "    print(run_nltk_tokenizer(lower_case(sentence)))\n",
    "    print(\"===================NLTK Tokenizer REMOVE STOP WORDS===================\")\n",
    "    print(remove_stop_words(sentence))   \n",
    "    print(\"===================NLTK Tokenizer REMOVED PUNCTUATION===================\")\n",
    "    print(run_nltk_tokenizer(remove_punctuation(sentence)))\n",
    "    print(\"===================NLTK Tokenizer REMOVED TAGS===================\")\n",
    "    print(run_nltk_tokenizer(remove_tags(sentence)))\n",
    "    print(\"===================NLTK Tokenizer REMOVED CHARS AND DIGITS===================\")\n",
    "    print(run_nltk_tokenizer(remove_special_chars_and_digits(sentence)))\n",
    "    print(\"===================NLTK Tokenizer STEMMING APPLIED===================\")\n",
    "    print(run_nltk_tokenizer(apply_stemming(sentence)))\n",
    "    print(\"===================NLTK Tokenizer LEMMATIZATION APPLIED===================\")\n",
    "    print(run_nltk_tokenizer(apply_lemmatization(sentence)))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest rescue-slash-revenge film to hit our screens, Taken, tries to walk the fine line between the two classic character archetypes - family man and ultimate badass.\n",
      "When the estranged seventeen year old daughter of a former spy (Liam Neeson) is kidnapped while holidaying overseas, her father must call upon his unique skill set in order to rescue her before she becomes lost to the Eastern-European slave trade.\n",
      "Liam Neeson kicking ass, and the potential of Maggie Grace showing a little - Taken had my full and undivided attention.\n",
      "As with the majority of films that limp onto the silver screen these days, everything seems to be a remake of a remake, or at the very least, a rehash of a tired idea.\n",
      "What separates a stock-standard retelling, from something that will stay with you longer than a half-masticated corn kernel stuck in your teeth, will almost certainly come down to the execution.\n",
      "Take a well-worn concept, freshen it up a little, but ultimately pull it off with dedication and skill.\n",
      "While Taken is by no means perfect, it is a prime example of a well-executed retelling.\n",
      "Let's face it, the concept of a tough guys daughter getting kidnapped, and having said tough guy track her down, defeating a million bad guys in the process is hardly anything new.\n",
      "It's basically the plot of Commando, or a dozen similar films for that matter.\n",
      "What Taken does well is to play on this tried-and-true formula; it adds depth to the usual one-dimensional characters, and mixes it up in a giant cocktail shaker with stylistic elements that made films like The Bourne Identity such crowd-pleasers.\n",
      "Our first encounter with former spy, Bryan, is less than exhilarating.\n",
      "You'd almost expect to see some incredible action set piece from his pre-retirement days, something that adequately introduces our brooding badass' action hero qualifications - negative.\n",
      "What we get is the image of Bryan asleep on the lounge at home, a well-thumbed pamphlet for a karaoke machine on his lap.\n",
      "He's after the perfect gift for his seventeen year old daughter's birthday, and from what we can establish, he's terribly indecisive when it comes to purchasing a present.\n",
      "It's kind of amusing that after less than two minutes of screen time, we've probably already experienced more character development and insight into our main character than we would experience in just about any other similar film.\n",
      "Amusing, and sad.\n",
      "On the surface, Bryan doesn't appear to be that different from you or I, he seemingly has the same faults, shortcomings and fears that we all do.\n",
      "It's not until his daughter is kidnapped that we see an entirely different side of Bryan emerge.\n",
      "Following on from the initial character development, the film moves quickly onto the search for Kim, Bryan's daughter.\n",
      "With Bryan as our guide, we navigate the murky underworld of Paris, our former spy using every trick in his book to find clues of his daughter's whereabouts.\n",
      "Without giving away too much of the story from this point, our lead character pulls out all the stops.\n",
      "The action set pieces are amazing and uncompromising in their realism and brutality, and while there are occasional moments where the suspension of disbelief is crucial, for the most part it's very much on the money.\n",
      "Guns boom with a satisfying reverb, bullets hit their mark with dead-eye accuracy, and Bryan proves that nothing is sacred when it comes to getting his daughter back alive.\n",
      "Now I'll be honest and say that Taken wasn't entirely perfect - I did have a few criticisms of the film.\n",
      "My first, and major beef was with our lead characters detective work when it came to tracking-down his daughter - somehow it all seemed far too 'path of least resistance', the quickest way to get from Point A to Point B.\n",
      "Everything felt too easy, even for a man who used to be a highly-trained intelligence operative.\n",
      "Rather than simply moving from one clue to the next, knowing exactly where to go and how to play his cards, I would have preferred to have had another fifteen or so minutes to pad out this side of the story - maybe even throwing in a few failed lines on inquiry just to make it a little more believable.\n",
      "Secondly, there were a few holes in the logic, like a particular scene where Bryan pretends to be a French police officer/intelligence operative, using a completely stock standard American accent - who the hell would buy that?\n",
      "Apparently the bad guys did.\n",
      "And last but not least, I did pick-up on a few editing issues.\n",
      "Take the scene where Bryan collects a fiber of the bad guys clothing - absolutely pointless.\n",
      "Nothing ever came of this scene.\n",
      "However that was minor compared to the most innocuous editing issue - key parts of the kidnap scene that seem to have gone missing.\n",
      "What do I mean?\n",
      "Well, I don't remember the daughter Kim yelling out any information on her attackers, as instructed by her father... yet Bryan seemed to have it all on tape when he passed it off to his CIA buddy for analysis.\n",
      "Overall, Taken was a pleasant surprise.\n",
      "It's often difficult to tell what to expect from these types of co-funded foreign films, but this one was certainly worth the money.\n",
      "While some of the initial 'detective work' by Neeson's character seemed very effortless and simply the easiest way to get from Point A to Point B, i.e.\n",
      "straight into the action, the action scenes themselves certainly made up for any shortcomings.\n",
      "No punches were pulled.\n",
      "The world our characters inhabited was dark, unforgiving, and morally ambiguous, and as a result, the methods used to get his daughter back were as equally dark, unforgiving, and morally ambiguous.\n",
      "Forget about Bond and Bourne - these guys ain't got anything on Liam Neeson.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'taken': 6, 'well': 5, 'bryan': 4, 'get': 4, 'daughter': 4, 'little': 3, 'point': 3, 'liam neeson': 2, 'former spy': 2, 'kidnapped': 2, ...})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore different extractors and difference preprocessing techniques\n",
    "all_terms=[]\n",
    "for sentence in sentences_nine:\n",
    "    print(sentence)\n",
    "    #pick your favorite term extractor\n",
    "    all_terms = all_terms +run_rake(sentence)\n",
    "#get the frequency distribution across the terms\n",
    "fd=get_freq_dist(all_terms)\n",
    "fd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
